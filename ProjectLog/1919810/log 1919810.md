
# 1.结构化数据加载
---

项目使用了面向对象编程对NFL全部的数据都可以实施结构化的加载，这种加载方式具有条理清晰的好处，并且在一个版本中实现了所加载的数据集对象本身就是可迭代的对象，大大简化了后续开发过程中对于数据调用的复杂性。

#### 细节:  
- `PffData, PlayData, TrackingData` 这三个主要`name`的数据分别对应 `pffScoutingData.csv, plays.csv, week{number}.csv` 这三种数据集文件  
- 对应的实现了对应的 `Game{name}` 类作为每一场game对应的数据集 和 `{name}Item` 类作为每一条数据的对象。`Game{name}` 类是可以遍历的对象，支持`__getitem__`方法  
- 同时，基于这三个数据，根据`gameId`+`playId`的唯一性，将三个数据表连接到了一起，组成了一个新的 `name` 名为 `NFLData` 的数据集对象

使用时非常方便，只需要调用对应class的.load 方法就会返回一个key为gameId的，对应每场比赛的`Game{name}Data`类，比如说: `games = GameNFLData.loads(['xxx'])`, 然后对于任意一个gameId的任意index的数据都可以这样轻易调用: `games['114514'][index]`

如此，对于后续的开发非常的友善。

# 2.自动数据预处理
---

这个功能有两个版本
1. 一个是面向开发者的结构化数据集对象，每个都支持直接调用.tensor()函数直接获取可以供神经网络使用的，已经自动完成预处理的数据。只需要输入name of columns作为输入特征集以及在对象成员中的目标特征，就可以获得对应的tensor。自动预处理技术是通过统计整个数据集中的信息，对于categories自动生成labels表，然后将其转为index编码这种神经网络可接受的输入信息；对于数字数据，则会将其自动计算归一化；对于时间数据则会将其转为时间戳。同时，函数也支持对于label表的覆盖：resize_range_overwrite 和 category_labels_overwrite参数中有覆盖配置的特征，函数会直接使用覆盖的配置，而不是用自动生成的统计功能，这是一个可扩展性非常高的设计。
2. 另一个版本则是以非常清晰简易易于理解的方式去加载数据，并且将dataframe作为属性存储在对象中。这一版的自动预处理和归一化功能会变得更加简明且易于理解，在不丢失易用性的同时很大程度上增加了易读性和通用性。首先被加载的`TrackingNormData `, `PffNormData`, `PlayNormData`, `GameNormData`, `PlayerNormData`, `MergeNormData` 这几个对象作为init参数给到数据生成器DataGenerator中，数据的条件过滤可以在这之前直接对上述几个类操作，也可以使用DataGenerator生成后的数据进行操作。因为数据生成器支持直接生成tensor的继承了torch.utils.data.Dataset的SimpleDataset类，也可以返回numpy数组或者dataframe。同时生成器的`generate_dataset`函数要求x_columns, y_column的输入，也如上个版本一样，会自动处理label数据和数字数据，对数字数据是否执行归一化，也可以由norm flag决定。在这一版中对于数据预处理提供了更加自由的自定义方法：直接使用data_type_mapping参数，这个参数是一个字典，其中key是column名，value是一个函数，就等于是执行python里面的map操作，这给了使用者更多的自定义空间。

# 0.1对于数据合并方式的探索

由于数据集分为了好几个数据文件以及类型，其中有些id并不是完全唯一的，无法直接合并。
这个合并方法就需要通过对数据集的***研究***来得出

- 标识符相关:  
  - gameid是每场比赛的独立标识符  
  - nflid是球员的独立标识符  
  - playid在追踪数据中的每场比赛并不唯一  
    - *在每场比赛的追踪数据中，nflid+playid`不能`作为唯一标识符*  
    - *在每场比赛的球探数据中，nflid+playid`可以`作为唯一标识符，不会在一场比赛中重复*  
    - 当在追踪数据中同一场中筛选相同的playid+gameid时，会发现frameId是一个连续的数字，推断：playId可能代表游戏中的一个阶段，因为对应的时间戳的跨度只有 4.1s`左右（这是一个均值, 最大`20s`，最小`1.8s`）  
    - # 图
    - ![Pasted%20image%2020240501005922.png](Pasted%20image%2020240501005922.png)
    - **所以，通过上述的事实，可以得出结论：每场比赛中的球探数据的`nflid+playid`组成的联合id，可以对应每场比赛中的一个时间段，这个时间段只有平均`4.1`秒，这是合理的，且可以使用的数据联合方式**
    - 在实施初步对数据集的探索后发现，plays.csv和tracking data中单场比赛的playId unique列表相同，也就意味着可以将数据关联   

在完成了对数据合并方式的***探索***以后，使得我们可以在前面的基础结构化数据类(GamePffData,GameTrackingData, GamePlayData)的基础上, 实现一个将基础数据合并以后的数据类GameNFLData. 

在现有基础上，进一步在下一代的数据加载代码中引入了更加方便的合并方式: 该版本的数据合并更加的迅速且简单。MergeNormData接受已经完成加载的`TrackingNormData `, `PffNormData`, `PlayNormData`, `GameNormData`, `PlayerNormData`作为输入参数，内部会自动对tracking，pff，play这三个最重要的数据实施合并。其余两者只需要在有需要的时候进行合并。比如说在生成器`DataGenerator`的`generate_dataset`函数支持的player_needed=False, game_needed=False这两个参数，就是控制生成数据集中是否包含player数据和game数据的。

# 3.建模与验证

建模的过程非常的坎坷

在技术路线上，一开始选择了使用LSTM/GRU进行测试，测试特征则是trackingdata和以pffblocktype为目标特列的数据。
![Pasted%20image%2020240501014908.png](Pasted%20image%2020240501014908.png)
![Pasted%20image%2020240501014919.png](Pasted%20image%2020240501014919.png)
![Pasted%20image%2020240501015148.png](Pasted%20image%2020240501015148.png)
![Pasted%20image%2020240501015155.png](Pasted%20image%2020240501015155.png)
当时对于这个条件的序列标记任务的实验如下:
第一次实验显示结果为80%的准确率，最终94%的准确率 
# tensorboard 截图
随后进行了尝试分割数据序列，结果并没有对准确率造成负面影响，但是加速了训练过程

也进行了对transformer的实验:
- 实验概要: 在原有基础上实施Transformer模型，测试性能
- 实验结果: 不如LSTM/GRU
- # maybe 出图
- ![Pasted%20image%2020240501013441.png](Pasted%20image%2020240501013441.png)
- 实验结论:
    - 实施Transformer模型后，发现在训练过程中，模型收敛速度较慢，且准确率提升较慢
    - 由于Transformer模型的特性，可能不适合当前的数据集，因此，不如LSTM/GRU模型

### 3.2从这里开始就开是疯狂碰壁

进行一些胜率模型的实验：
- 试验概要: 实现一场比赛的输赢模型的训练
- 实验结果: 失败
# tensorboard 截图 
- 试验结论:
    - 试验是根据 playdata中的 `preSnapHomeScore` 列和 `preSnapVisitorScore` 列判断一场比赛对主场是否胜利的，但是很明显以此训练的是序列分类模型，是失败的
    - 试验还为了排除序列分类模型设计问题，测试了另一种方式，也就是让序列标记模型对表记主场队伍得分，结果依然是失败，同时也考虑了其他pff数据的信息
    - 可以得出结论，`preSnapHomeScore` 和 `preSnapVisitorScore` 与主要数据之间，并不存在可见的有效关联，并不存在可以让神经网络所学习的特征
    - ![Pasted%20image%2020240501024253.png](Pasted%20image%2020240501024253.png)

最终因为不太了解NFL，而准备进行大规模实验，开发了非常容易替换训练参数的方法然后实施实验： 
## 3.3为了大规模实验的开发:
### 实施内容: 实施神经网络模型的构建

#### 细节:

- 实现了通用LSTM GRU序列标记网络
- 实现了训练config
- 支持任意输入输出label，比如说可以在配置中修改`input_feature`和`output_feature`，来选择NFLData中的任意数据作为输入输出，实现了非常自由化的实验功能。使得后续批量进行控制变量法实验变得非常容易。
- 构建了通用化的实验配置例子

## 3.4实验: 大规模控制变量对比实验

- 实验概要: 实施大规模控制变量对比实验, 基于GRU序列表及模型对于多个目标特征进行实验
- 实验结果: 有效目标特征: `pff_role`(76% 5 epoch), `pff_playAction`(63% 5epoch 无变化，需要改进)
- ![Pasted%20image%2020240501025019.png](Pasted%20image%2020240501025019.png)
# tensorboard 截图
- 实验结论:
    - 实验用到的特征有:
        - passResult.json
        - personnelD.json
        - personnelO.json
        - pff_passCoverage.json
        - pff_passCoverageType.json
        - pff_playAction.json
        - pff_positionLinedUp.json
        - pff_role.json
        - playResult.json
        - prePenaltyPlayResult.json
        - ![Pasted%20image%2020240501025304.png](Pasted%20image%2020240501025304.png)
        - ![Pasted%20image%2020240501025408.png](Pasted%20image%2020240501025408.png)
    - 实验实施了大规模控制变量对比实验，基于GRU序列表及模型对于多个目标特征进行实验
    - 实验结果显示，`pff_role` 特征的预测准确率可以达到76%（5 epoch）随着后续训练预期可以超过94%，而 `pff_playAction` 特征的预测准确率只有63%（5 epoch），且没有变化，需要进一步改进
    - 绝大部分特征无法从以tracking data为基础的数据中学习到什么有用的信息 

- 构造了训练过程的实现

### 4. 最终有效的多个模型+UI构建

在重新构建了数据集的加载方式以后，重新构建训练方式，最终发现了问题所在，数据集并不干净，被na污染。并且虽然数据是序列数据0，但是实质上数据集并不适合序列训练，同时，在实验过程中发现，其序列也并不重要。
同时，通过Gradio构建UI，将神经网络+机器学习，和视频可视化对接到UI上，增加人机交互。
# Na plot
![Pasted%20image%2020240501030447.png](Pasted%20image%2020240501030447.png)
### 4.2神经网络

在此，只需要一个非常简单的MLP分类器，即可完成绝大部分工作，甚至不需要怎么调参数。因为此时ui版本的自定义输入/输出训练器已经搭建完毕。因此只需要在ui界面上修改多选框就能轻易改变训练的策略，我们尝试了passResult，personnelO，personnelD，以及各种组合，神经网络均能显示出较强的泛用能力，并且能够在验证数据集中获得高于90%的准确率，个别比较难以处理的特征，也能至获得的80%的准确率

### 4.1随机森林

随机森林的训练自由度和神经网络的训练工具所提供的差不多，同时也可以实现很高的验证集准确率

## 3.1 Validation Scheme

我们所实施的模型验证均符合数据科学对于一个模型时间应用性能的验证惯例。也就是***验证集*** 和 ***训练集*** 没有 ***交集***，并且验证集和训练集在原始数据中的分割，是***随机分割***。以此确保在模型上验证的数据，是模型没有在训练中见过的数据，以此确保模型的泛用性和可推广性。

## 3/5 数据可视化

目前数据可视化分为两个方向

## 3.5 比赛的视频形式可视化

- 实现了数据可视化的基本功能，可以播放tracking data的数据
- 实现了可视化数据生成mp4的功能
- 同时在ui中支持这个功能，以及选择可以在底部实现什么数据
- 在底部数据的显示功能中，实现了可以显示任意数量的数据列信息，同时提供了模板功能，以进一步增加其客制化的程度。

## 5 统计学可视化

~~目前暂时没有在ui中支持统计学的可视化工具，因为这个工具在ui中的实现需要更加的客制化和自由化，受限于gradio的非动态组件加载，需要更多的研究开发去实现。~~

但是目前已经根据组员的建议实现了各种特定的所需的可视化：
- 所有队伍的平均prePenaltyPlayResult
- 所有PassResult对于每个队伍的频率统计图
- 对于每个队伍都生成一张关于指定进攻队形的防御配置（包括defndersInBox，personnelD， pff passCoverage，pff pass Coverage type）

- UI 
	- 防御配置可视化：对于每个队伍都生成一张关于指定进攻配置（可选offenseFormation 和 personnelO）的防御配置（包括defndersInBox，personnelD， pff passCoverage，pff pass Coverage type）
	- 单图信息统计：允许生成prePenaltyPlayResult和passResult对于每个队伍的频率统计
	- 单图多队信息统计：对于选择的主题数据列（比如说formations win/lose/draw），生成plot，在plot中每个子图都对应一个队伍的数据。


上述代码均对接到了UI中，并且提供一定程度上的自由选择，比如说生成时可以生成什么图片，以及指定队伍的plot等。
### 3.4.2模型输入特征分析

这个是针对神经网络的。对于完成训练的神经网络模型。我设计了一套工具，通过调用**Captum**库去计算每个输入特征值的贡献比重，如此可以分析哪些对结果造成了更多的影响。以此可以进行一些进一步的分析

这个已经在神经网络训练UI处实现，在训练完以后支持对该神经网络进行输入特征贡献分析，支持只对正确label分类，或者根据选择对每个选中的类执行输入特征贡献分析：![b6d69c93affd0fe055f2b1415fe9a5a.png](Pasted%20image%2020240501030447.png)
工具支持直接选择想要计算的label值，也可以设置采样的上限次数，采样越多，数据对于模型的描述越客观。
#### 一些基于现在实验得出的结论
首先是关于gameClock的，如果在训练数据中移除gameClock，会导致预测的数据的准确度从96%骤降至60%，很明显gameClock是很重要的。但是在图片中外卖可以看到，反而gameClock所占比例并不是很大。我猜测，在这里利用梯度计算出来的每个输入特征的贡献比，可以理解为对于每个输入特征类变化幅度的放大倍率。由于gameClock是线性增长的，其变化值一般性都比较稳定，有固定的方向，因此神经网络不必耗费过多的权重去放大gameClock。

以及一些其他有趣的事情，比如说当passResult结果为IN的时候，输入权重绝大多数都被聚集到了yardsToGo这一项（92%），这很有趣，这代表当预测结果是IN的时候，起到决定性作用的是yardsToGo这个数据列。而在C的结果中，defenderInBox，yardsToGo比较重要。当passResult是I的时候则是quater和gameClock比较重要。

![Pasted%20image%2020240501020603.png](Pasted%20image%2020240501020603.png)
![Pasted%20image%2020240501020628.png](Pasted%20image%2020240501020628.png)
![Pasted%20image%2020240501020619.png](Pasted%20image%2020240501020619.png)
![Pasted%20image%2020240501020740.png](Pasted%20image%2020240501020740.png)
